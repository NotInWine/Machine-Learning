# 线性回归原理分享-分享稿

大家好下面开始本次的分享，分享的主题是线性回归的一个算法介绍，以及他的推导过程，时间允许的话还有一个小示例程序辅助分享

1. 序
分享材料主要分为两部分
    1. 是背景介绍，讲一下线性回归的定义和算法特性
    2. 就是线性回归函数的推导过程，中间会省略一些数学上的细节，比如一部分的函数求导过程和矩阵求导过程等，
    因为分享的重点是求解思路和概念应用上的分享，所以我也没有太刻意地去回忆一些数学细节上的知识

2. 背景
    线性回归是一种回归算法，属于监督学习的一种，区别与分类算法，分类算法只能得到给定的标签，而回归算法得到具体的数值。它在经济，物理，金融等领域有着广泛的应用
    - 优点
        1. 可解释性强
        2. 逻辑检点，速度快
        3. 涉及机器学习领域很多基础思想和数据处理手段，适合作为一个机器学习入门课程来学习
    - 缺点
        1. 不适合非线性特征场景
        线性回归一定不适合非线性场景的，但是线性回归算法经过简单的加工是可以改变为非线性模型的，很多非线性数据经过处理也可以变为线性特征数据
        这就看我们在实际应用中如何取舍选择算法了。

3. 示例
我们通过一个例子来推以下线性回归方程。下图是模拟一个银行贷款记录，包含客户信息和额度，后面就用这个数据为例推以下回归方程，来预测客户的贷款额度。
我们设工资为，年龄为，然后可以工资和年龄对额度的影响系数为-1.2.。 然后我们就可以得到一个二元一次方程。

4. 坐标系-推导为矩阵形式，形成最终的
因为欸肉的特征，我们可以知道 他的值一定是 接近于零的最多，随着觉得值的增大而主键减小的。那么如果我们的函数的求解是接近最优解或者就是最优解的话，我们可以假定欸肉的分布是符合正太分布的

5. 正太分布
